h1. About

Experimental new data transformation workflows for the lobid-organisations data set based on "Metafacture":https://github.com/culturegraph/metafacture-core/wiki.

Currently transforms two data sets from Pica-XML and CSV to JSON-LD for Elasticsearch indexing.

_Note: for the currently productive transformations see "https://github.com/lobid/lodmill":https://github.com/lobid/lodmill_

h1. Setup

h2. Build

"!https://secure.travis-ci.org/hbz/lobid-organisations.png?branch=master!":https://travis-ci.org/hbz/lobid-organisations

Prerequisites: Java 8, Maven 3; verify with @mvn -version@

Create and change into a folder where you want to store the projects:

* @mkdir ~/git ; cd ~/git@

Build the hbz metafacture-core fork:

* @git clone https://github.com/hbz/metafacture-core.git@
* @cd metafacture-core@
* @mvn clean install -DskipTests@
* @cd ..@

Build lobid-organisations:

* @git clone https://github.com/hbz/lobid-organisations.git@
* @cd lobid-organisations@
* @mvn clean install@

See the @.travis.yml@ file for details on the CI config used by Travis.

h2. Tests

The build described above executes tests of the Metamorph transformations.

These tests are defined in XML files with a @test_@ prefix corresponding to the tested Metamorph files:

in @src/main/resources@:

@morph-dbs.xml@
@morph-enriched.xml@
@morph-sigel.xml@

in @src/test/resources@:

@test_morph-dbs.xml@
@test_morph-enriched.xml@
@test_morph-sigel.xml@

For details, see the "Metamorph testing framework documentation":https://github.com/culturegraph/metafacture-core/wiki/Testing-Framework-for-Metamorph.

h2. Eclipse

The processing pipelines are written in Java, the actual transformation logic and tests are written in XML. Both can be comfortably edited using Eclipse, which provides content assist (auto-suggest), Maven support, and direct execution of tests and the transformation.

* Download and run the "Eclipse Java IDE":https://www.eclipse.org/downloads/packages/eclipse-ide-java-developers/lunar, close the welcome screen and import metafacture-core and lobid-resources: 
* @File@ -> @Import...@ -> @Maven@ -> @Existing Maven Projects...@ -> @Next@ -> @Browse...@ -> select @~/git@ -> @Finish@
* Follow the instructions for installing additional plugins and restart Eclipse when it asks you to
* Set up the XML schemas for content assist and documentation while editing metamorph and metamorph-test files:
* @Window@ (on Mac: @Eclipse@) -> @Preferences@ -> @XML@ -> @XML Catalog@
* select @User Specified Entries@ -> @Add...@ -> @Workspace...@ -> @metafacture-core/src/main/resources/schemata/metamorph.xsd@
* repeat previous step for @metamorph-test.xsd@ in the same location

h1. Data

h2. Workflow

The source data sets are the _Sigelverzeichnis_ ('Sigel', format: PicaPlus-XML) and the _Deutsche Bibliotheksstatistik_ ('DBS', format: CSV). The transformation is implemented by a pipeline with 3 logical steps:

* Preprocess Sigel data, use DBS ID as record ID
* Preprocess DBS data, use DBS ID as record ID
* Enrich the DBS data with transformed Sigel data

Each of these steps has a corresponding Java class, Morph definition, and output file.

h2. Downloads

Optional: replace the sample data with the full input data dumps (only works hbz internally!):

* @cd src/main/resources/input/@
* @wget http://quaoar1.hbz-nrw.de:7001/assets/data/dbs.zip; unzip dbs.zip@
* @wget http://quaoar1.hbz-nrw.de:7001/assets/data/sigel.zip; unzip sigel.zip@

Optional: download the latest update of the Sigel data:

* @wget -O sigel/sigel-picaplus-updates-2014.xml http://services.d-nb.de/oai/repository?set=bib&verb=ListRecords&metadataPrefix=PicaPlus-xml&from=2014-01-01&until=2014-12-31@

h2. Transform

Go to the project root, run the transformation and change into the output directory:

* @cd ../../../../@
* @mvn exec:java -Dexec.mainClass="flow.Enrich"; cd src/main/resources/output/@

h2. Index

Import the data into Elasticsearch (only works hbz internally!):

* @curl -s -XPOST http://weywot2.hbz-nrw.de:9200/_bulk --data-binary @enriched.out.json; echo@

h2. Query

Query the resulting index (only works hbz internally!):

* @curl -XGET 'http://weywot2.hbz-nrw.de:9200/organisations/_search?q=name:hbz+OR+altLabel:hbz'; echo@

For details on the various options see the "query string syntax documentation":http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax.

Get a specific record by DBS ID:

* @curl -XGET 'http://weywot2.hbz-nrw.de:9200/organisations/dbs/ZY571'; echo@

Exclude the metadata (you can paste the resulting document into the "JSON-LD Playground":http://json-ld.org/playground/ for conversion tests etc.):

* @curl -XGET 'http://weywot2.hbz-nrw.de:9200/organisations/dbs/ZY571/_source'; echo@

For details on the various options see the "GET API documentation":http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/docs-get.html.

h2. Web

The @web/@ directory contains a basic web app implemented with Play to serve the JSON-LD context as @application/ld+json@ with CORS support. This is required to use the JSON-LD from third party clients, e.g. the "JSON-LD Playground":http://json-ld.org/playground/. It also provides proxy routes for Elasticsearch queries via HTTP (see index page of the web app for details).

Set up the Play application:

* @cd ~@
* @wget http://downloads.typesafe.com/typesafe-activator/1.2.10/typesafe-activator-1.2.10-minimal.zip@
* @unzip typesafe-activator-1.2.10-minimal.zip@
* @cd git/lobid-organisations/web@
* @~/activator-1.2.10-minimal/activator run@

Open @http://localhost:9000/organisations@

h1. License

Eclipse Public License: "http://www.eclipse.org/legal/epl-v10.html":http://www.eclipse.org/legal/epl-v10.html
